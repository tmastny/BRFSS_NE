---
title: "Chapter 1 Notes"
author: "Tim"
date: "11/5/2017"
output: 
  html_document:
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, 
                      results='show', cache=TRUE, autodep=TRUE)
```
## Sampling Method Assumptions

Requirements for a probability sample:

1. Every individual in the population must have a non-zero probability ($\pi_i$ for person $i$) to be included in the sample.

2. The probability $\pi_i$ must be known for each individual who ends up in the survey.

3. Every pair of individuals in the sample must have a non-zero probability of both ending up in the sample (written $\pi_{ij}$ for the pair of individuals $(i, j )$ ) .

4. The probability $\pi_{ij}$ must be known for every pair that does end up in the sample.

## Sampling Weights

Example: we have a simple random sample of 3500 individuals from California, which has a population of 35 million. Then there is a 

```{r}
3500/35000000
```

chance of any one person being included in the survey.

Effectively, each person in our sample represents 10000 Californias. Supposing 400 respondents had high blood pressure, then

```{r}
400*10000
```

is the expected amount in the total population.

"The fundamental statistical idea behind all of design-based inference is that an individual sampled with a sampling probability of $\pi_i$ represents $1/\pi_i$ individuals." Therefore, $1/\pi_i$ is the sampling weight.


We can also use the the sampling weight to measure other outcomes. For example, the unbaised estimate for income is 
\[ \hat{T_{\text{income}}} = \frac{1}{\pi_i} \cdot \text{income}_i \]

In general, for measurable outcome $X_i$ on individual $i$, we say that
\[\hat{X_i} = \frac{1}{\pi_i}\cdot X_i\]
Then total measurement for a population is estimated from a sample size $n$ by
\[\hat{T_X} = \sum_{i=1}^n \hat{X_i}\]

See page 5 for the variance of the measure and why we need to make sure $\pi_{ij}$ is non-zero. 

\[V(\hat{T_X}) = \sum_{i,j}\frac{X_iX_j}{\pi_{ij}} - \frac{X_iX_j}{\pi_i\pi_j}\]

## Design Effect

"The design effect was defined by Kish (1965) as the ratio of a variance of an estimate in a complex sample to the variance of the same estimate in a simple random sample."


## Exercises

1.3 c: Each reader of the website does not have a non-zero probability. Some readers may not access the website through the front page, but only through links to articles are social media. 

1.4 You are conducting a survey that will estimate the proportion of women who used anti-malarial insecticide-treated bed nets every night during their last pregnancy. With a simple random sample you would need to recruit 50 women in any subpopulation where you wanted a standard error of less than 5 percentage points in the estimate. You are using a sampling design that has given design effects of 2-3 for proportions in previous studies in similar areas.

  a) Will you need a larger or smaller sample size than 50 for a subpopulation to get the desired precision?

  b) Approximately what sample size will you need to get the desired precision?

#### Answer: 
Let $P$ be the proportion of women who used the net. Then $P_R$ is the estimated proportion based of a random sample of 50 women, with SE (standard error) 0.05. 

Our design effect is 2-3; let's use 3 for the worst case scenario. Let $d=3$ be the design effect and let $P_C$ be the proportion estimate in a complex survey. Then 
\[d = V(P_C)/V(P_R) = 3\]
Moreover, the standard error of a proportion is 
\[SE_p = \sqrt{ p(1 - p) / n }\]

We know
\begin{align*}
0.05 \geq SE_{P_R} = \sqrt{ P_R(1 - P_R) / 50 }
\end{align*}

For our complex survey, we want
\begin{align*}
0.05 \geq SE_{P_C} = \sqrt{ P_C(1 - P_C) / n }
\end{align*}

And we know 
\begin{align*}
\frac{V(P_C)}{V(P_R)} &= \frac{  n SE_{P_C}^2   }{50 SE_{P_R}^2} = 3 \\
n &= 3 \cdot 50(0.05)^2/(0.05)^2 = 150
\end{align*}



